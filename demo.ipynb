{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/blob/main/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TABLE OF CONTENTS**"
      ],
      "metadata": {
        "id": "xgl4XoSJHuxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Introduction](#scrollTo=Mey2sVO3w06m)\n",
        "\n",
        ">>[Abstract](#scrollTo=Mey2sVO3w06m)\n",
        "\n",
        ">>[How to Run the Project](#scrollTo=Mey2sVO3w06m)\n",
        "\n",
        ">[Overview of the Used Machine Learning Techniques](#scrollTo=ZDfbtUw36j_1)\n",
        "\n",
        ">>[Architectures](#scrollTo=ZDfbtUw36j_1)\n",
        "\n",
        ">>>[Disclamer](#scrollTo=ZDfbtUw36j_1)\n",
        "\n",
        ">>[Q-values prediction](#scrollTo=ZDfbtUw36j_1)\n",
        "\n",
        ">>[Classical MLP](#scrollTo=ZDfbtUw36j_1)\n",
        "\n",
        ">>[Attention Model](#scrollTo=HU4Z78Kv9hiW)\n",
        "\n",
        ">>[DGN](#scrollTo=_s_7VNFm91w8)\n",
        "\n",
        ">>[DQN](#scrollTo=G5-kiKLj98yv)\n",
        "\n",
        ">>[CommNet](#scrollTo=VK8i3VvG-Bg-)\n",
        "\n",
        ">>[State Aggregation](#scrollTo=AGSMkNTI-KIH)\n",
        "\n",
        ">>>[SUM](#scrollTo=AGSMkNTI-KIH)\n",
        "\n",
        ">>>[GCN](#scrollTo=7S-b66SX-TyK)\n",
        "\n",
        ">[Selecting Parameters](#scrollTo=1Ei12632gg3Z)\n",
        "\n",
        ">>[Common Parameters in the Sweep](#scrollTo=1Ei12632gg3Z)\n",
        "\n",
        ">>[CommNet specific](#scrollTo=1Ei12632gg3Z)\n",
        "\n",
        ">>[DQN, DGN specific](#scrollTo=1Ei12632gg3Z)\n",
        "\n",
        ">[Advice for Parameter Selection](#scrollTo=OhkNKLaYlGRj)\n",
        "\n",
        ">>[CommNet settings](#scrollTo=OhkNKLaYlGRj)\n",
        "\n",
        ">>[DQN, DGN settings](#scrollTo=OhkNKLaYlGRj)\n",
        "\n",
        ">>[Aggregation Type](#scrollTo=OhkNKLaYlGRj)\n",
        "\n",
        ">[Our results](#scrollTo=S8nU4WQLwJI7)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "Ud4C609CHs-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authors: Michal Bělohlávek, Tomáš Procházka\n",
        "\n",
        "# Introduction\n",
        "Welcome to the demo file, where one can run the project with zero effort and see the results and visualistaion for themselves. While this is an easy and plesant way to enjoy this Neural Net, we strongly urge anyone who visits this demo to run the project as it was intended, expand upon it and improve it.\n",
        "\n",
        "## Abstract\n",
        "This project was created and submited as the final semestral project for the Machine Learning 2 class on FNSPE CTU. This project concerns itself with reinforcement learning for multiple agents controlled by a single neural net in a graph environment. The core aim of this project is to provide a neural network solution that efficiently navigates multiple planes along a fully connected graph with the goal of estimating the shortest path, while avoiding collisions of planes. We implemented an enhanced version of a classical replay buffer that samples experiences based on the predicted future reward to assist the learning process. We also added regularization techniques, since the dimensionality of our problem is much larger compared to the on in the repository we cite.\n",
        "\n",
        "## How to Run the Project\n",
        "For those who decide to download the project and run the training on their PC, please beware of the configurations. A basic setup is present in /data as demo_config.yaml\n",
        "\n",
        "Setting up capacity, minibatch_size or sequence_length too high may result in freezing the computer.\n",
        "\n",
        "Most hyperparameters may be changed in the config.yaml file. If you intend to do your own sweeps on weights and biases, we have also uploaded a version of the main file wandb_main.py that supports sweep configuration.\n",
        "\n",
        "If you however decide to only run the project in this demo file, note that any pre-trained models are too large to upload to the GitHub repo directly, so the training will be done from scratch here. The training will use the demo_confing with small number of steps and generally \"low\" settings, so taht the training can be completed in reasonable amount of time. Therefore, one should expect very poor results compared to the results we present at the end of this notebook.\n",
        "\n",
        "**To see the training and results, simply run the following code boxes.**\n"
      ],
      "metadata": {
        "id": "Mey2sVO3w06m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview of the Used Machine Learning Techniques\n",
        "## Architectures\n",
        "\n",
        "<span><font color=\"green;\">\n",
        "###Disclamer\n",
        "\n",
        "**The following code is used as an illustration only, to see the functionalities of the code directly, visit the /src file on our GitHub repo. This approach was taken because it is not feasible to copy the whole code into Colab.**\n",
        "</font></span>\n",
        "\n",
        "(Or maybe it would be feasible but that would be an extreme violation of our hard work.)\n",
        "\n",
        "This file contains the description of the main architectures used within this project. Below we provide a detailed description for all of them.\n",
        "\n",
        "First we describe models that were used for Q-values predictions:\n",
        "\n",
        "    - DGN\n",
        "    - DQN\n",
        "    - Comm_net,\n",
        "    \n",
        "then we go over the methods that were used to aggregate hidden graph representations:\n",
        "\n",
        "    - SUM\n",
        "    - GCN\n",
        "\n",
        "and lastly we describe the **NetMon** class, that was originally provided by the authors.\n",
        "\n",
        "## Reinforcement Learning\n",
        "First, let's introduce the concept of reinforcement learning with multiple agents. Each agent observes only a partial view of some environment and state information. Reinforcement Learning (RL) is a machine learning approach, where agents learn to make sequential decisions by interacting with an environment. Each agent hold a local and/or global observation of its environment. Through a process of trial and error, the agent receives rewards or penalties for their actions, enabling it to discover an optimal policy for achieving specific goals. In our case, for example, we used Epsilon-Greedy policy, where at the beginning the agent makes random decisions to explore the environment and allow itself to learn the interactions. Then it gradually transfers to learned behavior.\n",
        "\n",
        "In the context of multiple agents, Recurrent Neural Networks (RNNs) play a critical role in handling temporal dependencies. For example, in multi-agent RL, RNNs can be used to model and predict the behavior of agents based on sequences of past experiences, enabling better coordination and communication between agents. By maintaining hidden states that encapsulate the history of interactions, RNNs empowers agents to adapt to dynamic environments and collaborate effectively.\n",
        "\n",
        "Our work prouds itself amongst other things on the replay_buffer that significantly improved the prediction of paths that lead to future reward. A replay buffer is a key component in reinforcement learning that stores past experiences, typically in the form of state, action, reward, and next state tuples. For RNNs, which rely on sequential dependencies, replay buffers are particularly important as they allow the agent to learn from diverse trajectories while maintaining temporal coherence. By sampling batches of sequences instead of independent transitions, the replay buffer ensures that the RNN captures meaningful patterns over time, improving its ability to model long-term dependencies. Additionally, we implemented a version of replay buffer that samples the batch sequences based on maximizing the td_error, hence the mean square error between predicted future and immediate rewards. This allows the agents to learn and prioritize paths that lead to targets as that is the place of the most future reward.\n",
        "\n",
        "## Q-values Prediction\n",
        "We use Q-Net for q_value predictions, a reinforcement learning technique that assigns values to each future action for one step into the future based on agent's observations (state). In this particular setting, the Q-Net predicts the reward for each edge the agent could take at any given step. We implemented a node mask and generalized the setting to fit grahps with variable edge count for each node. The algorithm in Q-Net implements dynamic programming weighted by the learning rate hyperparameter.\n",
        "\n",
        "$$Q_{target} = (1-lr) * Q_{now} + lr * E[R_{t+1}(a_{t+1}, s_{t+1}) + \\gamma * max_{a}Q_{next}(a_{t+1}, s_{t+1})| s_t],$$\n",
        "\n",
        "where $R_{t+1}(a_{t+1}, s_{t+1})$ is sampled from batch of experiences. From this formulation, we can se that sampling the batch indices that maximize the td_error, we essentially grow the $Q_{now}$ values for future steps.\n",
        "\n",
        "The goal of each agent is to maximize the expected future reward weighted by the gamma (discount) factor\n",
        "\n",
        "$$max E[\\sum_{t=t_0}^T \\gamma^{t-t_0}R_{t}(a_t, s_t)].$$\n",
        "\n",
        "## Classical MLP\n",
        "MLP is a feed forward network that passes the input thourgh many linear layers with activation functions. In our case, we used leaky-ReLU as the activation function. It is also possible to modify this setting to for example GeLU in the config.yaml file but we should points out that this may lead to the agent learning to take forbidden edges, that are subsequently masked leading to insufficient gradient flow. This approach has not been explored in this project. Dropout is included for regularization."
      ],
      "metadata": {
        "id": "ZDfbtUw36j_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    This is the underlying module for all used models within this work.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, mlp_units, activation_fn, activation_on_output = True):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.activation = activation_fn\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "\n",
        "        self.linear_layers = nn.ModuleList() # Storage for L layers\n",
        "        previous_units = in_features\n",
        "\n",
        "        # Transform units into a list\n",
        "        if isinstance(mlp_units, int):\n",
        "            mlp_units = [mlp_units]\n",
        "\n",
        "        # Create a chain of layers\n",
        "        for units in mlp_units:\n",
        "            self.linear_layers.append(nn.Linear(previous_units, units))\n",
        "            previous_units = units\n",
        "\n",
        "        self.out_features = previous_units\n",
        "        self.activation_on_ouput = activation_on_output\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Inter layers\n",
        "        for module in self.linear_layers[:-1]:\n",
        "            x = module(x)\n",
        "            if self.activation is not None:\n",
        "                x = self.activation(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        # Pass through the last layer\n",
        "        x = self.linear_layers[-1](x)\n",
        "        if self.activation_on_ouput:\n",
        "            x = self.activation(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "7gDhEfU66-5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Model"
      ],
      "metadata": {
        "id": "HU4Z78Kv9hiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttModel(nn.Module):\n",
        "    \"\"\"\n",
        "        Basic attention model with with masking and scaling.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, k_features, v_features, out_features, num_heads, activation_fn, vkq_activation_fn):\n",
        "        super(AttModel, self).__init__()\n",
        "\n",
        "\n",
        "        self.k_features = k_features\n",
        "        self.v_features = v_features\n",
        "        self.num_heads = num_heads      # Number of attention heads\n",
        "\n",
        "        self.fc_v = nn.Linear(in_features, v_features * num_heads)  # Transforming input features into Values for attention\n",
        "        self.fc_k = nn.Linear(in_features, k_features * num_heads)  # Transforming input features into Keys for attention\n",
        "        self.fc_q = nn.Linear(in_features, k_features * num_heads)  # Transforming input values into Queries for attention\n",
        "\n",
        "        self.fc_out = nn.Linear(v_features * num_heads, out_features)   # Transforms the outputs from all attention heads into output dimension\n",
        "\n",
        "        self.activation = activation_fn\n",
        "        self.vkq_activation = vkq_activation_fn     # Activation function that can be applied into Values, Keys, Queries\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        Defining the scaling factor for attention as 1/ sqrt(d_k), this is the same as the publishing paper \"Attention is All You Need\".\n",
        "        This is done for the purpose of reducing the gradient so it does not become too large. Later you will see that without it, the dot product\n",
        "        would grow too large without the scaling\n",
        "        \"\"\"\n",
        "        self.attention_scale = 1 / (k_features **0.5)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, x, mask):\n",
        "        batch_size, num_agents = x.shape[0], x.shape[1]\n",
        "\n",
        "        \"\"\"\n",
        "        The code below does the following:\n",
        "            - a linear mapping is applied on the inputs to obtain Values, Keys, Queries\n",
        "            - the Values, Keys, Queries are then reshaped to separate the different attention heads of the model\n",
        "            :reshape: will result in (batch_size, num_agents, num_heads, features_per_head)\n",
        "\n",
        "        Visual representation:\n",
        "            Input x\n",
        "            |\n",
        "            [Linear Layers] -> V, Q, K\n",
        "            |\n",
        "            [Optional Activation] (vkq_activation_fn)\n",
        "            |\n",
        "            [Reshape for Multi-Head]\n",
        "            |\n",
        "            [Transpose for Heads]\n",
        "            |\n",
        "            [Compute Attention Weights (Dot Product, Scale, Mask, Softmax)]\n",
        "            |\n",
        "            [Apply Attention to Values]\n",
        "            |\n",
        "            [Skip Connection]\n",
        "            |\n",
        "            [Transpose and Concatenate Heads]\n",
        "            |\n",
        "            [Final Linear Layer and Activation]\n",
        "            |\n",
        "            Output\n",
        "        \"\"\"\n",
        "\n",
        "        v = self.fc_v(x).view(batch_size, num_agents, self.num_heads, self.v_features)\n",
        "        q = self.fc_q(x).view(batch_size, num_agents, self.num_heads, self.k_features)\n",
        "        k = self.fc_k(x).view(batch_size, num_agents, self.num_heads, self.k_features)\n",
        "\n",
        "        if self.vkq_activation is not None:\n",
        "            v = self.vkq_activation(v)\n",
        "            q = self.vkq_activation(q)\n",
        "            k = self.vkq_activation(k)\n",
        "\n",
        "        # We rearrange the tensors to shape (batch_size, num_heads, num_agents, features_per_head)\n",
        "        # This is done so we can perform batch multiplication over the batch size and heads\n",
        "        q, k, v = q.transpose(1,2), k.transpose(1,2), v.transpose(1,2)\n",
        "\n",
        "        # Add head axis (we are keeping the same mask for all attention heads)\n",
        "        mask = mask.unsqueeze(1)    # (batch_size, 1, num_agents, num_agents) (1,1,20,20)\n",
        "\n",
        "        \"\"\"\n",
        "        The attention is calculated as a dot product of all queries with all keys,\n",
        "            while scaling it with the attention scale so it does not explode.\n",
        "            - q is of shape             (batch_size, num_heads, num_agents, features_per_head)\n",
        "            - k transposed is of shape  (batch_size, num_heads, features_per_head, num_agents)\n",
        "            - the multiplication result is of shape (batch_size, num_heads, num_agents, num_agents)\n",
        "        :masked_fill sets positions where mask == 0 to a large negative value - removes them from the attention computation practically\n",
        "        \"\"\"\n",
        "\n",
        "        att_weights = torch.matmul(q, k.transpose(2, 3)) * self.attention_scale\n",
        "        att = att_weights.masked_fill(mask==0, -1e9)\n",
        "        att = F.softmax(att, dim=-1)    # Softmax is applied along the last dimension to obtain normalized attention probabilities\n",
        "        att = self.dropout(att)\n",
        "\n",
        "        # Now we combine the Values with respect to the attention we just computed\n",
        "        \"\"\"\n",
        "            - att is of shape (batch_size, num_heads, num_agents, num_agents)\n",
        "            - v is of shape (batch_size, num_heads, num_agents, v_features)\n",
        "            - the multiplication result is of shape (batch_size, num_heads, num_agents, v_features)\n",
        "        \"\"\"\n",
        "        out = torch.matmul(att, v)\n",
        "\n",
        "        # We add a skip connection\n",
        "        out  = torch.add(out, v)    # This additionally promotes gradient flow and mitigates vanishing gradient\n",
        "\n",
        "        # Now \"remove\" the transpose and concatenate all heads together\n",
        "        \"\"\"\n",
        "            - out is of shape (batch_size, num_heads, num_agents, v_features)\n",
        "            - out after transpose is of shape (batch_size, num_agents, num_heads, v_features)\n",
        "            - contiguous() ensures that the tensor is stored in a contiguous chunk of memory so that the reshape for view can happen\n",
        "            - view is used to reshape the tensor to (batch_size, num_agents, v_features), therefore, we flatten the last two dimensions\n",
        "                into a single one (num_heads * v_features)\n",
        "            - final out is of shape  (batch_size, num_agents, num_heads * v_features)\n",
        "        \"\"\"\n",
        "\n",
        "        out = out.transpose(1,2).contiguous().view(batch_size, num_agents, -1)\n",
        "        out = self.activation(self.fc_out(out)) # Linear map into a desired feature dimension\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        return out, att_weights"
      ],
      "metadata": {
        "id": "Zol8QsIS9nS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DGN\n"
      ],
      "metadata": {
        "id": "_s_7VNFm91w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DGN(nn.Module):\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, mlp_units, num_actions, num_heads, num_attention_layers, activation_fn, kv_values):\n",
        "        super(DGN, self).__init__()\n",
        "\n",
        "        self.encoder = MLP(in_features, mlp_units, activation_fn)\n",
        "        self.att_layers = nn.ModuleList()\n",
        "        hidden_features = self.encoder.out_features\n",
        "\n",
        "        print(\"In features of DGN: \", in_features)\n",
        "        print(\"MLP units are: \", mlp_units)\n",
        "\n",
        "        for _ in range(num_attention_layers):\n",
        "            self.att_layers.append(\n",
        "                AttModel(hidden_features, kv_values, kv_values, hidden_features, num_heads, activation_fn, activation_fn)\n",
        "                                   )\n",
        "\n",
        "        self.q_net = Q_Net(hidden_features * (num_attention_layers + 1), num_actions)\n",
        "\n",
        "        self.att_weights = []\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"\"\"\n",
        "        Additional comment to the function:\n",
        "            - each attention layer refines the representation h by focusing on relevant parts of the input\n",
        "            - by concatenating the representations the feature set for the Q-network is enhanced, consequently making more informed decisions\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        h = self.encoder(x)     # Encodes the input featuers, has a shape of (batch_size, num_agents, hidden_features)\n",
        "        q_input = h     # Initialize the q_input with encoded features\n",
        "        self.att_weights.clear()    # Ensuring that attention weights from previous forward passes do not accumulate\n",
        "\n",
        "        for attention_layer in self.att_layers:\n",
        "            h, att_weight = attention_layer(h, mask)\n",
        "            self.att_weights.append(att_weight)\n",
        "\n",
        "            # Concatenation of outputs\n",
        "            q_input = torch.cat((q_input, h), dim=-1)\n",
        "\n",
        "        # Final q_input is of shape (batch_size, num_agents, hidden_features * (num_attention_layers +1))\n",
        "        q = self.q_net(q_input)\n",
        "\n",
        "        return q    # is of shape (batch_size, num_agents, num_actions)\n"
      ],
      "metadata": {
        "id": "Pgg1EA3J94Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DQN\n",
        "\n",
        "Deep Q-Learning Network. The encoder MLP transforms input features for generalization purposes that are then passed to the Q_Net to predict the reward for possible actions. Forward action to process the input. While being arguably the simplest model we have, DQN had the best and most consistent performance. This has also been noted by the authors of the graph MARL paper we reference."
      ],
      "metadata": {
        "id": "G5-kiKLj98yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "    \"\"\"\n",
        "    Introduces simple Deep Feed Forward Neural Network( = MLP) as the encoder.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, mlp_units, num_actions, activation_fn):\n",
        "        super(DQN, self).__init__()\n",
        "\n",
        "        self.encoder = MLP(in_features, mlp_units, activation_fn)   # Encodes incoming features\n",
        "        self.q_net = Q_Net(self.encoder.out_features, num_actions)  # Outputs Q-values\n",
        "        self.activation = activation_fn\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        batch, agent, features = x.shape\n",
        "        h = self.encoder(x)\n",
        "        q = self.q_net(h)\n",
        "        return q\n"
      ],
      "metadata": {
        "id": "Vx3Sl8CB99oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CommNet"
      ],
      "metadata": {
        "id": "VK8i3VvG-Bg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DQNR(nn.Module):\n",
        "    \"\"\"\n",
        "    Recurrent DQN with an lstm cell.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, mlp_units, num_actions, activation_fn):\n",
        "        super(DQNR, self).__init__()\n",
        "        self.encoder = MLP(in_features, mlp_units, activation_fn)\n",
        "        self.lstm = nn.LSTMCell(\n",
        "            input_size=self.encoder.out_features, hidden_size=self.encoder.out_features\n",
        "        )\n",
        "        self.state = None\n",
        "        self.q_net = Q_Net(self.encoder.out_features, num_actions)\n",
        "\n",
        "    def get_state_len(self):\n",
        "        return 2 * self.lstm.hidden_size\n",
        "\n",
        "    def _state_reshape_in(self, batch_size, n_agents):\n",
        "        \"\"\"\n",
        "        Reshapes the state of shape\n",
        "            (batch_size, n_agents, self.get_state_len())\n",
        "        to shape\n",
        "            (2, batch_size * n_agents, hidden_size).\n",
        "\n",
        "        :param batch_size: the batch size\n",
        "        :param n_agents: the number of agents\n",
        "        \"\"\"\n",
        "        self.state = (\n",
        "            self.state.reshape(\n",
        "                batch_size * n_agents,\n",
        "                2,\n",
        "                self.lstm.hidden_size,\n",
        "            )\n",
        "            .transpose(0, 1)\n",
        "            .contiguous()\n",
        "        )\n",
        "\n",
        "    def _state_reshape_out(self, batch_size, n_agents):\n",
        "        \"\"\"\n",
        "        Reshapes the state of shape\n",
        "            (2, batch_size * n_agents, hidden_size)\n",
        "        to shape\n",
        "            (batch_size, n_agents, self.get_state_len()).\n",
        "\n",
        "        :param batch_size: the batch size\n",
        "        :param n_agents: the number of agents\n",
        "        \"\"\"\n",
        "        self.state = self.state.transpose(0, 1).reshape(batch_size, n_agents, -1)\n",
        "\n",
        "    def _lstm_forward(self, x, reshape_state=True):\n",
        "        \"\"\"\n",
        "        A single lstm forward pass\n",
        "\n",
        "        :param x: Cell input\n",
        "        :param reshape_state: reshape the state to and from (batch_size, n_agents, -1)\n",
        "        \"\"\"\n",
        "        batch_size, n_agents, feature_dim = x.shape\n",
        "        # combine agent and batch dimension\n",
        "        x = x.view(batch_size * n_agents, -1)\n",
        "\n",
        "        if self.state is None:\n",
        "            lstm_hidden_state, lstm_cell_state = self.lstm(x)\n",
        "        else:\n",
        "            if reshape_state:\n",
        "                self._state_reshape_in(batch_size, n_agents)\n",
        "            lstm_hidden_state, lstm_cell_state = self.lstm(\n",
        "                x, (self.state[0], self.state[1])\n",
        "            )\n",
        "\n",
        "        self.state = torch.stack((lstm_hidden_state, lstm_cell_state))\n",
        "        x = lstm_hidden_state\n",
        "\n",
        "        # undo combine\n",
        "        x = x.view(batch_size, n_agents, -1)\n",
        "        if reshape_state:\n",
        "            self._state_reshape_out(batch_size, n_agents)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        h = self.encoder(x)\n",
        "        h = self._lstm_forward(h)\n",
        "        return self.q_net(h)\n",
        "\n",
        "\n",
        "class CommNet(DQNR):\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features,\n",
        "        mlp_units,\n",
        "        num_actions,\n",
        "        comm_rounds,\n",
        "        activation_fn,\n",
        "    ):\n",
        "        super().__init__(in_features, mlp_units, num_actions, activation_fn)\n",
        "        assert comm_rounds >= 0\n",
        "        self.comm_rounds = comm_rounds\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        batch_size, n_agents, feature_dim = x.shape\n",
        "        h = self.encoder(x)\n",
        "\n",
        "        # manually reshape state\n",
        "        if self.state is not None:\n",
        "            self._state_reshape_in(batch_size, n_agents)\n",
        "\n",
        "        h = self._lstm_forward(h, reshape_state=False)\n",
        "\n",
        "        # explicitly exclude self-communication from mask\n",
        "        mask = mask * ~torch.eye(n_agents, dtype=bool, device=x.device).unsqueeze(0)\n",
        "\n",
        "        for _ in range(self.comm_rounds):\n",
        "            # combine hidden state h according to mask\n",
        "            # first add up hidden states according to mask\n",
        "            #    h has dimensions (batch, agents, features)\n",
        "            #    and mask has dimensions (batch, agents, neighbors)\n",
        "            #    => we have to transpose the mask to aggregate over all neighbors\n",
        "            c = torch.bmm(h.transpose(1, 2), mask.transpose(1, 2)).transpose(1, 2)\n",
        "            # then normalize according to number of neighbors per agent\n",
        "            c = c / torch.clamp(mask.sum(dim=-1).unsqueeze(-1), min=1)\n",
        "\n",
        "            # skip connection for hidden state and communication\n",
        "            h = h + c\n",
        "            # use new hidden state\n",
        "            self.state[0] = h.view(batch_size * n_agents, -1)\n",
        "\n",
        "            # pass through forward module\n",
        "            h = self._lstm_forward(h, reshape_state=False)\n",
        "\n",
        "        # manually reshape state in the end\n",
        "        self._state_reshape_out(batch_size, n_agents)\n",
        "        return self.q_net(h)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IpEpQrpz-Ejb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## State Aggregation\n",
        "\n",
        "### SUM"
      ],
      "metadata": {
        "id": "AGSMkNTI-KIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleAggregation(nn.Module):\n",
        "    def __init__(self, agg: str, mask_eye: bool) -> None:\n",
        "        super().__init__()\n",
        "        self.agg = agg\n",
        "        assert self.agg == \"mean\" or self.agg == \"sum\"\n",
        "        self.mask_eye = mask_eye\n",
        "\n",
        "    def forward(self, node_features, node_adjacency):\n",
        "        if self.mask_eye:\n",
        "            node_adjacency = node_adjacency * ~(\n",
        "                torch.eye(\n",
        "                    node_adjacency.shape[1],\n",
        "                    node_adjacency.shape[1],\n",
        "                    device=node_adjacency.device,\n",
        "                )\n",
        "                .repeat(node_adjacency.shape[0], 1, 1)\n",
        "                .bool()\n",
        "            )\n",
        "        feature_sum = torch.bmm(node_adjacency, node_features)\n",
        "        if self.agg == \"sum\":\n",
        "            return feature_sum\n",
        "        if self.agg == \"mean\":\n",
        "            num_neighbors = torch.clamp(node_adjacency.sum(dim=-1), min=1).unsqueeze(-1)\n",
        "            return feature_sum / num_neighbors\n"
      ],
      "metadata": {
        "id": "PCj3k7NC-NsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GCN\n",
        "GCN is a graph convolutional operator that handles Message Passing phase within the GNN. Implementation is available at [GCN](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html#torch_geometric.nn.conv.GCNConv) within the pytorch_geometric library that specializes on GNNs.\n",
        "\n",
        "GCN is based on the spectral approximations of convolutional"
      ],
      "metadata": {
        "id": "7S-b66SX-TyK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QM2J9VFu-WPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NetMon"
      ],
      "metadata": {
        "id": "ojoJfBcX-Wrm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4BRf0oL5-X7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Qg4P8isqT8SB",
        "outputId": "504d0725-7c8b-439f-8598-11e8bd7c5fe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '2024-final-letadylka-prochazka-belohlavek'...\n",
            "remote: Enumerating objects: 528, done.\u001b[K\n",
            "remote: Counting objects: 100% (302/302), done.\u001b[K\n",
            "remote: Compressing objects: 100% (195/195), done.\u001b[K\n",
            "remote: Total 528 (delta 156), reused 208 (delta 101), pack-reused 226 (from 1)\u001b[K\n",
            "Receiving objects: 100% (528/528), 14.32 MiB | 22.67 MiB/s, done.\n",
            "Resolving deltas: 100% (258/258), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the main.py script with the modified config\n",
        "!python /content/2024-final-letadylka-prochazka-belohlavek/src/main.py --config data/config_comm.yaml"
      ],
      "metadata": {
        "id": "ypBUnsbfUgem",
        "outputId": "ceaacb0c-9e07-4bca-8475-f6aeb1b682e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-12 10:11:59.841513: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-12 10:11:59.878132: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-12 10:11:59.887487: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-12 10:11:59.924750: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.0 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/2024-final-letadylka-prochazka-belohlavek/src/main.py\", line 29, in <module>\n",
            "    from torch.utils.tensorboard.writer import SummaryWriter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py\", line 12, in <module>\n",
            "    from .writer import FileWriter, SummaryWriter  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\", line 19, in <module>\n",
            "    from ._embedding import get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/_embedding.py\", line 10, in <module>\n",
            "    _HAS_GFILE_JOIN = hasattr(tf.io.gfile, \"join\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 50, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
            "    import tensorflow\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\", line 47, in <module>\n",
            "    from tensorflow._api.v2 import __internal__\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.__internal__ import autograph\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
            "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
            "    from tensorflow.python.autograph.utils import ag_logging\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
            "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
            "    from tensorflow.python.framework import ops\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\", line 46, in <module>\n",
            "    from tensorflow.python import pywrap_tfe\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/pywrap_tfe.py\", line 25, in <module>\n",
            "    from tensorflow.python._pywrap_tfe import *\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: _ARRAY_API not found\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.0 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/2024-final-letadylka-prochazka-belohlavek/src/main.py\", line 29, in <module>\n",
            "    from torch.utils.tensorboard.writer import SummaryWriter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py\", line 12, in <module>\n",
            "    from .writer import FileWriter, SummaryWriter  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\", line 19, in <module>\n",
            "    from ._embedding import get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/_embedding.py\", line 10, in <module>\n",
            "    _HAS_GFILE_JOIN = hasattr(tf.io.gfile, \"join\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 50, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
            "    import tensorflow\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\", line 47, in <module>\n",
            "    from tensorflow._api.v2 import __internal__\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.__internal__ import autograph\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
            "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
            "    from tensorflow.python.autograph.utils import ag_logging\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
            "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
            "    from tensorflow.python.framework import ops\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\", line 49, in <module>\n",
            "    from tensorflow.python.client import pywrap_tf_session\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/pywrap_tf_session.py\", line 19, in <module>\n",
            "    from tensorflow.python.client._pywrap_tf_session import *\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: _ARRAY_API not found\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.0 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/2024-final-letadylka-prochazka-belohlavek/src/main.py\", line 29, in <module>\n",
            "    from torch.utils.tensorboard.writer import SummaryWriter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py\", line 12, in <module>\n",
            "    from .writer import FileWriter, SummaryWriter  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\", line 19, in <module>\n",
            "    from ._embedding import get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/_embedding.py\", line 10, in <module>\n",
            "    _HAS_GFILE_JOIN = hasattr(tf.io.gfile, \"join\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 50, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
            "    import tensorflow\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\", line 47, in <module>\n",
            "    from tensorflow._api.v2 import __internal__\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 11, in <module>\n",
            "    from tensorflow._api.v2.__internal__ import distribute\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/distribute/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.__internal__.distribute import combinations\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/distribute/combinations/__init__.py\", line 8, in <module>\n",
            "    from tensorflow.python.distribute.combinations import env # line: 456\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/combinations.py\", line 33, in <module>\n",
            "    from tensorflow.python.distribute import collective_all_reduce_strategy\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\", line 25, in <module>\n",
            "    from tensorflow.python.distribute import cross_device_ops as cross_device_ops_lib\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/cross_device_ops.py\", line 28, in <module>\n",
            "    from tensorflow.python.distribute import cross_device_utils\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/cross_device_utils.py\", line 22, in <module>\n",
            "    from tensorflow.python.distribute import values as value_lib\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/values.py\", line 23, in <module>\n",
            "    from tensorflow.python.distribute import distribute_lib\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 205, in <module>\n",
            "    from tensorflow.python.data.ops import dataset_ops\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/__init__.py\", line 21, in <module>\n",
            "    from tensorflow.python.data import experimental\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/__init__.py\", line 98, in <module>\n",
            "    from tensorflow.python.data.experimental import service\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/service/__init__.py\", line 419, in <module>\n",
            "    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\", line 26, in <module>\n",
            "    from tensorflow.python.data.ops import dataset_ops\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 34, in <module>\n",
            "    from tensorflow.python.data.ops import iterator_ops\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 45, in <module>\n",
            "    from tensorflow.python.training.saver import BaseSaverBuilder\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/saver.py\", line 50, in <module>\n",
            "    from tensorflow.python.training import py_checkpoint_reader\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\", line 19, in <module>\n",
            "    from tensorflow.python.util._pywrap_checkpoint_reader import CheckpointReader\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "AttributeError: _ARRAY_API not found\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
            "    from tensorboard.compat import notf  # noqa: F401\n",
            "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/2024-final-letadylka-prochazka-belohlavek/src/main.py\", line 29, in <module>\n",
            "    from torch.utils.tensorboard.writer import SummaryWriter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py\", line 12, in <module>\n",
            "    from .writer import FileWriter, SummaryWriter  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\", line 19, in <module>\n",
            "    from ._embedding import get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/_embedding.py\", line 10, in <module>\n",
            "    _HAS_GFILE_JOIN = hasattr(tf.io.gfile, \"join\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\", line 50, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
            "    import tensorflow\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\", line 47, in <module>\n",
            "    from tensorflow._api.v2 import __internal__\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 11, in <module>\n",
            "    from tensorflow._api.v2.__internal__ import distribute\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/distribute/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.__internal__.distribute import combinations\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/__internal__/distribute/combinations/__init__.py\", line 8, in <module>\n",
            "    from tensorflow.python.distribute.combinations import env # line: 456\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/combinations.py\", line 33, in <module>\n",
            "    from tensorflow.python.distribute import collective_all_reduce_strategy\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\", line 25, in <module>\n",
            "    from tensorflow.python.distribute import cross_device_ops as cross_device_ops_lib\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/cross_device_ops.py\", line 28, in <module>\n",
            "    from tensorflow.python.distribute import cross_device_utils\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/cross_device_utils.py\", line 22, in <module>\n",
            "    from tensorflow.python.distribute import values as value_lib\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/values.py\", line 23, in <module>\n",
            "    from tensorflow.python.distribute import distribute_lib\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 205, in <module>\n",
            "    from tensorflow.python.data.ops import dataset_ops\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/__init__.py\", line 21, in <module>\n",
            "    from tensorflow.python.data import experimental\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/__init__.py\", line 98, in <module>\n",
            "    from tensorflow.python.data.experimental import service\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/service/__init__.py\", line 419, in <module>\n",
            "    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\", line 26, in <module>\n",
            "    from tensorflow.python.data.ops import dataset_ops\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 34, in <module>\n",
            "    from tensorflow.python.data.ops import iterator_ops\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 45, in <module>\n",
            "    from tensorflow.python.training.saver import BaseSaverBuilder\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/saver.py\", line 50, in <module>\n",
            "    from tensorflow.python.training import py_checkpoint_reader\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\", line 19, in <module>\n",
            "    from tensorflow.python.util._pywrap_checkpoint_reader import CheckpointReader\n",
            "SystemError: initialization of _pywrap_checkpoint_reader raised unreported exception\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download files from our Git repository\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NVIUhKxST-5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting Parameters\n",
        "We ran multiple sweeps on Weights & Biases to provide an overview of the parameter importance and correlations. Because of the time constraints for the project, we were not able to collect all the data we would like but regardless the results are reasonably clear. We selected the BEST models based on the gathered reward. Other interesting metrics would be spr (the mean ratio of the lenght of the path taken and the true shortest path) or throughput (mean ratio of the planes that reached the target during the episode).\n",
        "\n",
        "We ran two sweeps, one for only CommNet settings (first picture), the other sweep for comparing DQN and DGN (second picture). Both sweeps ran for 75k steps, with CommNet being significantly faster yet inferior architecture and Sum being the superior AND faster aggregation method.\n",
        "\n",
        "## Common Parameters in the Sweep\n",
        " - mini_batch_size : number of sampled experiences from the replay buffer\n",
        " - epsilon_decay : decay factor of epsilon in the EpsilonGreedy policy\n",
        " - agg_type : method used during GNN message aggregation phase\n",
        " - gamma: multiplicative factor in Q-Learning\n",
        "\n",
        "## CommNet specific\n",
        " - comm_round: number of information passing round\n",
        "\n",
        "## DQN, DGN specific\n",
        " - num_heads: number of attention heads\n",
        "\n"
      ],
      "metadata": {
        "id": "1Ei12632gg3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Advice for Parameter Selection\n",
        "Below we give advice how to fine tune the hyperparameters and then we show results from the sweeps on wandb. 35 sweeps were performed for the two settings.\n",
        "## CommNet settings\n",
        "It is apparent that selecting lower number of com_rounds as well as increasing the mini_batch_size improves the model greatly. Although the epsilon_update_frequency does not show as important, it could be due to the narrow range we selected for the sweep. We advice to set this parameter to about 70 for 75k steps and gradually increase this number with increasing number of steps. A good rule of thumb is that after the training the epsilon value should be around 0.01, where there is a hard line so that if epsilon dips below 0.01 it is reset to 0.01.\n",
        "## DQN, DGN settings\n",
        "Gamma seemed to be the most important hyperparameter in this setting, which is not all that surprising because of the architecture that goes almost directly into the Q_Net. We saw consistent improvement in the gathered reward with the gamma parameter being set lower (to around 0.92-0,95) for 75k steps. Epsilon update frequency shows here as a very important hyperparameter with a strong negative correlation. This means that epsilon should be updated more often, which suggests that the models are able to learn to navigate the environment quickly. The number of attention heads and attention layers shows a positive correlation with the reward.\n",
        "\n",
        "## Aggregation Type\n",
        "In both sweeps the aggregation type didn't hold much importance. In the case of CommNet the suggestion would be to use GCN on basis that GCN had positive correlation and SUM had negative correlation with the generated reward.\n",
        "On the other hand, in the case of DQN and DGN, SUM seemed to perform better. From our own experience from training the models for more steps, we would reccomend using SUM as it is faster and the results are comparable."
      ],
      "metadata": {
        "id": "OhkNKLaYlGRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WANDB sweep for CommNet\n",
        "![](https://github.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/blob/main/pictures/commnet.png?raw=true)"
      ],
      "metadata": {
        "id": "e1gjgCZZzhzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters importance for CommNet\n",
        "![](https://github.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/blob/main/pictures/commnet_parameters.png?raw=true)"
      ],
      "metadata": {
        "id": "ghDCmQ55xYYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WANDB sweep for DQN vs. DGN\n",
        "![](https://github.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/blob/main/pictures/dgn_dqn.png?raw=true)"
      ],
      "metadata": {
        "id": "TO3iriopz9P7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HYPERPARAMETERS IMPORTANCE FOR DGN and DQN\n",
        "![](https://github.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/blob/main/pictures/dgn_dqn_parameters.png?raw=true)"
      ],
      "metadata": {
        "id": "ca4DwESCxrjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Our results"
      ],
      "metadata": {
        "id": "S8nU4WQLwJI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eNkykOCkxXlU"
      }
    }
  ]
}