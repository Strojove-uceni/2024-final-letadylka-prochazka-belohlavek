{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/blob/main/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo file\n",
        "Authors: Michal Belohlavek, Tomas Prochazka\n",
        "## Intro\n",
        "Welcome to the demo file, where one can run the project with zero effort and see the results and visualistaion for themselves. While this is an easy and plesant way to enjoy this Neural Net, we strongly urge everyone to run the project as it was intended, expand upon it and improve it. If you seek a commented version of the code in the most miniscule detail, please take a look at our implementation in the GitHub repo.\n",
        "## Abstract\n",
        "This project was created and submited as the final semestral project for the Machine Learning 2 class on FNSPE CTU. We take the structure and code from the authors of Multi-Agent Reinforcement Learning in Graphs (reference in README). We modified, reshaped and added valuable parts to the original implementation to make it applicable to the problem of free routing and plane path navigation. The core aim of this project is to provide a rather fast neural network that navigates multiple planes along a graph with dynamically changing weights with the goal of reaching the target as fast as possible, while avoiding collisions. In this demo file, we demonstrate our work, provide an overview of the used techniques and give advice on how to select fine tuned hyperparameters.\n",
        "\n",
        "*For additional details, see our presentation on GitHub.*\n",
        "## Shoert overview of the used ML techniques\n",
        "\n",
        "## How to run the project\n",
        "### Selecting parameters\n",
        "### Advice for parameter selection\n",
        "\n",
        "## Our results\n"
      ],
      "metadata": {
        "id": "Mey2sVO3w06m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download files from our Git repository\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NVIUhKxST-5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the network.py file from GitHub\n",
        "!wget -q https://raw.githubusercontent.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/main/src/environment.py\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/main/src/eval.py\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/main/src/network.py\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/main/src/routing.py\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/main/src/policy.py\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/main/src/model.py\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/main/src/wrapper.py\n",
        "\n",
        "!wget -q https://github.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/tree/main/data/adj_mat_fixed.npy\n",
        "\n",
        "!wget -q https://github.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/tree/main/data/dist_mat_fixed.npy\n",
        "\n",
        "!wget -q https://github.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/tree/main/data/sparse_points_fixed.json\n",
        "\n",
        "!wget -q https://github.com/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/blob/main/src/config.yaml\n",
        "\n",
        "!pip install pyyaml"
      ],
      "metadata": {
        "id": "zmYi3QPlUsoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the files"
      ],
      "metadata": {
        "id": "0W-MTeWPeJ_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "\n",
        "adj_mat = np.load('adj_mat_fixed.npy')\n",
        "dist_mat = np.load('dist_mat_fixed')\n",
        "with open('sparse_points_fixed.json', 'r') as file:\n",
        "    sparse_points = json.load(file)\n",
        "\n",
        "import yaml\n",
        "\n",
        "with open('config.yaml', 'r') as file:\n",
        "    config = yaml.safe_load(file)"
      ],
      "metadata": {
        "id": "TLoOiq8GdMIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main.py adjusted for evaluation only"
      ],
      "metadata": {
        "id": "EkF-to75frGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from network import Network\n",
        "from environment import reset_and_get_sizes\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import traceback\n",
        "import json\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "from model import DGN, MLP, CommNet, NetMon, DQN\n",
        "from routing import Routing\n",
        "\n",
        "from wrapper import NetMonWrapper\n",
        "from policy import ShortestPath, EpsilonGreedy\n",
        "from pathlib import Path\n",
        "from torch.utils.tensorboard.writer import SummaryWriter\n",
        "from util import (\n",
        "    dim_str_to_list,\n",
        "    filter_dict,\n",
        "    get_state_dict,\n",
        "    interpolate_model,\n",
        "    load_state_dict,\n",
        "    set_attributes,\n",
        "    set_seed,\n",
        ")\n",
        "from eval import evaluate\n",
        "import sys\n",
        "from torch.utils.tensorboard.writer import SummaryWriter"
      ],
      "metadata": {
        "id": "WU108ndNfqQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize distance matrix\n",
        "dist_mat[adj_mat==0] = 0\n",
        "min = 1000\n",
        "for i in range(118):\n",
        "    for j in range(118):\n",
        "        if 0< dist_mat[i][j] < min:\n",
        "            min = dist_mat[i][j]\n",
        "max = np.max(dist_mat)\n",
        "\n",
        "new_min = 1\n",
        "new_max = 10\n",
        "dist_mat = ((dist_mat-min)/(max-min))*(new_max-new_min) + new_min\n",
        "\n",
        "config['only_eval']['eval'] = True # overwrite any setting to evaluate only\n",
        "if config['only_eval']['eval']:\n",
        "    assert Path(config['only_eval']['model_path']).exists()\n",
        "    loaded_dict = torch.load(config['only_eval']['model_path'], map_location='cpu')\n",
        "    loaded_model_arg_values = loaded_dict[\"args\"]\n",
        "    loaded_model_arg_values['only_eval'] = {}\n",
        "    loaded_model_arg_values['only_eval']['eval'] = True\n",
        "    loaded_model_arg_values['only_eval']['model_path'] = config['only_eval']['model_path']\n",
        "    config = loaded_model_arg_values\n",
        "    config['evaluation']['episodes'] = 10\n",
        "    config['evaluation']['episode_steps'] = 100\n",
        "    config['training']['mini_batch_size'] = 8\n",
        "    config['training']['sequence_length'] = 5\n",
        "    config['netmon']['iterations'] = 3\n",
        "    config['device'] = 'cpu'\n",
        "    for key in config:\n",
        "        if key == \"device\":\n",
        "            print(f\"{key}:  {config[key]}\")\n",
        "            continue\n",
        "        print(key)\n",
        "        for subkey in config[key]:\n",
        "            print(f\"\\t{subkey}: {config[key][subkey]}\")\n",
        "\n",
        "cbase = config['base']\n",
        "cnetmon = config['netmon']\n",
        "device = config['device']\n",
        "ctar_update = config['target_update']\n",
        "ceval = config['evaluation']\n",
        "ctraining = config['training']\n",
        "ceps = config['epsilon_greedy']\n",
        "\n",
        "# Define network environment\n",
        "network = Network(adj_mat, dist_mat, sparse_points)\n",
        "\n",
        "\n",
        "# Define type of environment\n",
        "env = Routing(network, cbase['n_planes'], cbase['env_var'], adj_mat, dist_mat, k=cbase['n_neighbors'], enable_action_mask=False)\n",
        "\n",
        "# Define activation function\n",
        "activation_function = getattr(F, cbase['activ_f'])\n",
        "\n",
        "# Dynamically resets the environment\n",
        "n_agents, agent_obs_size, n_nodes, node_obs_size = reset_and_get_sizes(env)\n",
        "\n",
        "print(\"Sizes before netmon:\")\n",
        "print(\"Agent observation size: \", agent_obs_size)\n",
        "print(\"Node observation size: \", node_obs_size)\n",
        "\n",
        "# Use NetMon - init is rather long :)\n",
        "netmon = NetMon(node_obs_size,  # 'in_features' in init\n",
        "                cnetmon['dim'],     # 'hidden_features' in init\n",
        "                cnetmon['enc_dim'] , # 'encoder_units' in init\n",
        "                iterations=cnetmon['iterations'],\n",
        "                activation_fn=activation_function,\n",
        "                rnn_type= cnetmon['rnn_type'], rnn_carryover=cnetmon['rnn_carryover'], agg_type=cnetmon['agg_type'],\n",
        "                output_neighbor_hidden=cnetmon['neighbor'], output_global_hidden=cnetmon['global']\n",
        "                ).to(device)    # Move to device\n",
        "\n",
        "\n",
        "# Get observations from the environment\n",
        "summary_node_obs = torch.tensor(env.get_node_observation(), dtype=torch.float32, device=device).unsqueeze(0)\n",
        "summary_node_adj = torch.tensor(env.get_nodes_adjacency(), dtype=torch.float32, device=device).unsqueeze(0)\n",
        "summary_node_agent = torch.tensor(env.get_node_agent_matrix(), dtype=torch.float32, device=device).unsqueeze(0)\n",
        "# Summarizes our current model - just to have it somewhere\n",
        "netmon_summary = netmon.summarize(summary_node_obs, summary_node_adj, summary_node_agent)\n",
        "node_state_size = netmon.get_state_size()\n",
        "\n",
        "node_aux_size = 0 if env.get_node_aux() is None else len(env.get_node_aux()[0]) # = n_waypoints\n",
        "\n",
        "# Now we wrap the whole netmon class with a Wrapper - agents will use observations from netmon\n",
        "env = NetMonWrapper(env, netmon, cnetmon['start_up_iters'])\n",
        "_, agent_obs_size, _, _ = reset_and_get_sizes(env)  # Observation length\n",
        "\n",
        "print(\"Sizes after netmon:\")\n",
        "print(f\"Node state size: {node_state_size}\")        # 256\n",
        "print(f\"Agent observation size with netmon: {agent_obs_size}\")  # 3263\n",
        "print(f\"Node auxiliary size: {node_aux_size}\")      # 0\n",
        "\n",
        "\n",
        "\n",
        "# In_features are 'agent_obs_size'\n",
        "# 'env.action_space.n' is equal to the number of neighbors - choices, 'num_actions' in DGN definition\n",
        "cdgn = config['dgn']\n",
        "if cbase['model_type'] == \"dgn\":\n",
        "    model = DGN(agent_obs_size, cdgn['hidden_dim'], env.action_space.n, cdgn['heads'], cdgn['att_layers'], activation_function, cdgn['kv_values']).to(device)\n",
        "elif cbase['model_type'] == \"comm_net\":\n",
        "    ccom_net = config['commnet']\n",
        "    model = CommNet(agent_obs_size, cdgn['hidden_dim'], env.action_space.n, comm_rounds=ccom_net['comm_rounds'], activation_fn=activation_function).to(device)\n",
        "elif cbase['model_type'] == \"dqn\":\n",
        "    model = DQN(agent_obs_size, cdgn['hidden_dim'], env.action_space.n, activation_function).to(device)\n",
        "else:\n",
        "    raise ValueError(\"Invalid model type\")\n",
        "\n",
        "\n",
        "# print(config)\n",
        "# Load paramters of model for quick evaluation\n",
        "if config['only_eval']['eval']:\n",
        "    assert Path(config['only_eval']['model_path']).exists()\n",
        "    load_state_dict(\n",
        "        torch.load(config['only_eval']['model_path'], map_location=device),\n",
        "        model,\n",
        "        netmon,\n",
        "    )\n"
      ],
      "metadata": {
        "id": "ZlsGA7KMglIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_tar = copy.deepcopy(model).to(device)     # Create a deep copy of the current model == DGN\n",
        "\n",
        "model = model.load_state_dict(torch.load('model.pth'))\n",
        "model_has_state = hasattr(model, \"state\")\n",
        "aux_model = None\n",
        "\n",
        "policy = EpsilonGreedy(env, model, env.action_space.n, epsilon=ceps['epsilon'], step_before_train=ctraining['step_before_train'], epsilon_update_freq=ceps['epsilon_update_freq'], epsilon_decay=ceps['epsilon_decay'])\n",
        "\n",
        "if config['only_eval']['eval']:\n",
        "    model.eval()\n",
        "    netmon.eval()\n",
        "    print(\"loaded\")\n",
        "    print(\"Performing Evaluation\")\n",
        "    metrics = evaluate(env, policy, ceval['episodes'], ceval['episode_steps'],\n",
        "                      True, \"eval_dict\", ceval['output_detailed'], ceval['output_node_state_aux']\n",
        "                      )\n",
        "    print(json.dumps(metrics, indent=4, sort_keys=True, default=str))\n",
        "    sys.exit(0)"
      ],
      "metadata": {
        "id": "di5NpByHiLPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "comment = \"_\"\n",
        "if hasattr(env, \"env_var\"):\n",
        "    comment += f\"R{env.env_var.value}\"\n",
        "comment += \"_netmon\"\n",
        "writer = SummaryWriter(comment=comment)\n",
        "print(\"Performing evaluation:\")\n",
        "metrics = evaluate(\n",
        "    env,\n",
        "    policy,\n",
        "    ceval['episodes'],\n",
        "    ceval['episode_steps'],\n",
        "    Path(writer.get_logdir()) /\"eval\",\n",
        "    ceval['output_detailed'],\n",
        "    ceval['output_node_state_aux']\n",
        ")\n",
        "paths_to_save = env.save_paths()\n",
        "print(json.dumps(metrics, indent = 4, sort_keys=True, default=str))\n",
        "\n",
        "for plane in env.planes:\n",
        "    print(plane.paths)\n",
        "\n",
        "env.plot_trajectory()"
      ],
      "metadata": {
        "id": "TLSBYNhNihQg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}