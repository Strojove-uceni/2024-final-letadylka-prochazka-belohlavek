{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Strojove-uceni/2024-final-letadylka-prochazka-belohlavek/blob/main/initial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d5EdjBNcppa"
      },
      "source": [
        "## Some overview\n",
        "- Growing Neural Gas\n",
        "- Graph Neural Networks\n",
        "\n",
        "### Curve + shortest path\n",
        "https://github.com/Octavian-ai/shortest-path - kinda old ([medium](https://medium.com/octavian-ai/finding-shortest-paths-with-graph-networks-807c5bbfc9c8))\n",
        "\n",
        "\n",
        "\n",
        "<!--\n",
        "Approach Outline:\n",
        "-  Initial Path: The starting point for optimization is a straight-line path represented by a Bézier curve with four control points.B(t) = (1-t)^3P_0 + 3(1-t)^2tP_1 + 3(1-t)t^2P_2 + t^3P_3 t in [0;1]P_0 ... starting point and P_3 ... end point\n",
        "\n",
        "- Dynamic Updates: The neural network adjusts the inner control points P_1 and P_2 of the Bézier curve to create an efficient trajectory.\n",
        "\n",
        "- Environment Feedback: Weather conditions are sampled along the curve division of interval [0;1]and the flight speed is dynamically adjusted based on environmental data.\n",
        "\n",
        "- Loss Function: The objective is to minimize total flight time calculated as the sum of the time it takes to traverse linear segments of the Bézier curvewhere time = sum distance_i / speed_i (speed is affected by weather)distance is simply |B(i+1) - B(i)| and speed_i = ||v_i||Full length of the Bezier curve can be calculated by applying Simpson's rule. The NN learn to adjust P_1 and P_2: Reinfocement learning -->"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TO READ\n",
        "- What are MLPs\n",
        "- Graphs\n",
        "- Graph Neural networks\n",
        "- Reinforcement learning\n",
        "- Multi-agent reinforcement learning\n",
        "- Imitation learning\n",
        "- Meta learning\n",
        "- Attention networks\n",
        "\n",
        "## Useful articles to read through\n",
        "They may not necessarily exactly mirror our work, but are insighful. Additionally, the refer to github, where individual implementaions can be found\n",
        "- [MALR on coordination graphs](https://medium.com/@jamgochian95/multi-agent-reinforcement-learning-with-coordination-graphs-428dddb99907)\n",
        "- [Former based approach for shortest path](https://medium.com/octavian-ai/finding-shortest-paths-with-graph-networks-807c5bbfc9c8)\n",
        "- [GNN for shortest path](https://medium.com/@bnn_upc/computing-the-shortest-path-with-graph-neural-networks-gnn-a-hands-on-introduction-to-ignnition-bea531b3b5b2)\n",
        "- [Interesting non-linear approach](https://www.sciencedirect.com/science/article/pii/S0096300306016304)\n",
        "- [Approximation of the shortest path](https://arxiv.org/pdf/2002.05257)\n",
        "- [Meta Learning intro](https://medium.com/huggingface/from-zero-to-research-an-introduction-to-meta-learning-8e16e677f78a)\n",
        "- [Multi agent meta learning](https://signalprocessingsociety.org/publications-resources/ieee-open-journal-signal-processing/dif-maml-decentralized-multi-agent-meta)\n",
        "- [Deep path](https://sites.cs.ucsb.edu/~william/papers/DeepPath.pdf)\n",
        "- [Shortest path with attention network](https://www.ijcai.org/proceedings/2019/569)\n",
        "\n",
        "## Some libraries to look into/try out\n",
        "Again, we may not use them in the end, but are good for starters.\n",
        "- https://github.com/jw3il/graph-marl?tab=readme-ov-file\n",
        "- https://github.com/Octavian-ai/shortest-path\n",
        "- https://imitation.readthedocs.io/en/latest/algorithms/gail.html\n",
        "- https://github.com/marcbrittain/Autonomous-ATC"
      ],
      "metadata": {
        "id": "Szb8etpQmOTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<u>Co plácáme?</u>\n",
        "Assume planes take of instantly to their flying altitude (35 000 - 36 000 ft.) and land when they reach their destination. Further assume that the planes move through waypoints that form an underlying graph. Every point in the graph is connected to N-closest neighbors.\n",
        "\n",
        "The goal is to optimize the routes of individual planes based on changing environment, the graph. Individual planes have to take into consideration other planes and changing weather. Additionally, planes have to follow safety constraints to not collide with others and safely travel to their destination.\n",
        "\n",
        "# <u>Jak to uplácáme?</u>\n",
        "## **MARL**\n",
        "Use graph as the underlying representation of waypoints and let agents move on the graph.\n",
        "\n",
        "<u>**First objective**</u>\n",
        "- create/find graph enviroment!\n",
        "- let the weights be static\n",
        "- run simple MARL just to play with it!\n",
        "\n",
        "What next?\n",
        "- try out reward functions, different policies\n",
        "- competition/ coordination/ mixed setup\n",
        "- create dynamic weights based on local weather\n",
        "- try different MARL setups: decentralized learning/centralized learning/centralized learning + decentralized execution\n",
        "- imitation learning - A* could be the expert algorithm/Floyd, would be implemented with Generative Adverisial Imitation Learning (GAIL)\n",
        "\n",
        "### **Environment**\n",
        "The environment will be implemented with [PettingZoo](https://pettingzoo.farama.org/). It is the Multi-agent version of classical Gym/Gymnasium by OpenAI. The training can then be performed with [Ray](https://docs.ray.io/en/latest/ray-overview/index.html) for example.\n",
        "\n",
        "### **Possible tryouts**\n",
        "\n",
        "We can then experiment with different approaches: [group-aware](https://arxiv.org/pdf/2404.10976), [stochastic graph](https://arxiv.org/pdf/2303.13213), [graph conv. RL](https://arxiv.org/pdf/1810.09202), [online marl](https://arxiv.org/pdf/2006.12841).\n",
        "Additionally, we might try out A*, where the heuristic function is the NN itself.\n",
        "\n",
        "I have not read through all of [this](https://arxiv.org/html/2404.04898v1), but looks nicely organised and commented. Maybe we could take something from them.\n",
        "\n",
        "#### Ad. GAIL\n",
        "GAIL - Generative Adversial Imitation Learning seems also nice. Basically the agents try to imitate the deciions of some expert until then become undistinguishable. We could design the expert as the A* algorithm that will look only one step ahead and decide based on the cost which path to take. The heuristic function could be some Euclidean distance.\n",
        "Additionally, we could look into Autocurricula, but that may be useless for us.\n",
        "\n",
        "## <u> GNNs </u>\n",
        "We can then try to move away from MARL to try out another approach - Graph Neural Networks.\n",
        "\n",
        "Our starting paper in this area is prolly [this](https://medium.com/@bnn_upc/computing-the-shortest-path-with-graph-neural-networks-gnn-a-hands-on-introduction-to-ignnition-bea531b3b5b2). Here we would use the Meassage passing NN to classify which points belong to the shortest path. Question is, how we could turn this into a multi-classification problem for different sources and destinations ~ more planes. That could be a great thing to create actually.\n",
        "\n",
        "\n",
        "Another approach could be with **Evolving GNNs**, where we could encode the weather and capacity of planes into the nodes of a GNN. Then, every time step, these would evolved. Consequently, we could predict the weights of edges between nodes and based on that use the basic shortest path finding algo for a single time step and update the planes completely separately.\n",
        "\n",
        "\n",
        "## Honarable mentions\n",
        "- There are special versions of the A* algorithm where the heuristic function is the deep NN itself and this function is learnt.\n",
        "- NN with Particle Swarm Optimization (PSO)\n",
        "- https://ojs.aaai.org/index.php/SOCS/article/view/18244\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zetkoSQumgvr"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}